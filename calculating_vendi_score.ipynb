{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "ATmQEpgFxA4Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f0d744a-143d-4e11-8d3a-d6d3e05cb58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers accelerate torchmetrics[image] diffusers vendi_score vendi_score[images] vendi_score[text,molecules] vendi_score[all]"
      ],
      "metadata": {
        "id": "ejL_LVI9NwOI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3661e33f-d5bf-46ac-98a0-39e5e26bf972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.29.3)\n",
            "Requirement already satisfied: torchmetrics[image] in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (0.27.2)\n",
            "Requirement already satisfied: vendi_score in /usr/local/lib/python3.10/dist-packages (0.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.22.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics[image]) (0.11.2)\n",
            "Requirement already satisfied: scipy>1.0.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics[image]) (1.11.4)\n",
            "Requirement already satisfied: torch-fidelity<=0.4.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics[image]) (0.3.0)\n",
            "Requirement already satisfied: torchvision>=0.8 in /usr/local/lib/python3.10/dist-packages (from torchmetrics[image]) (0.17.1+cu121)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (7.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (9.4.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1 in /usr/local/lib/python3.10/dist-packages (from vendi_score) (1.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from vendi_score) (3.7.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from vendi_score) (3.8.1)\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (from vendi_score) (2023.9.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics[image]) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1->vendi_score) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1->vendi_score) (3.4.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.18.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->vendi_score) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->vendi_score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->vendi_score) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->vendi_score) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->vendi_score) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->vendi_score) (2.8.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->vendi_score) (8.1.7)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->vendi_score) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uot2LXKeNjTH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from torch import nn\n",
        "from torchvision.models import inception_v3, Inception_V3_Weights\n",
        "from torchvision import transforms\n",
        "from vendi_score import image_utils, data_utils, vendi\n",
        "from PIL import Image\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", module=\"torchvision\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6c36a62f53ac40d58f7854a865912bc3",
            "78f00809c91e4940a967e337c3767a04",
            "422c5922e5c345cf885de5f40be5af26",
            "9ec0ab7f66344bd585e39b89320b078b",
            "14c46ea1a6e6435eac3cc291b1694b23",
            "29dedc07eed04018847e13aa81996866",
            "5a2caf2f17a64d1b9747915f4b2476c3",
            "087e09c98ca14c2b87125740a8761694",
            "39d0ff31f4da4077ad441676b251fd4a",
            "670006362981456a95057877f9adff64",
            "c2d965d79f444f50befefedad5707777"
          ]
        },
        "id": "23fDQG8RNjTJ",
        "outputId": "0390cf1b-5e12-4272-d25b-85c2d5dbcc09"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c36a62f53ac40d58f7854a865912bc3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "repo_ids = [\"runwayml/stable-diffusion-v1-5\", \"stabilityai/stable-diffusion-xl-base-1.0\"]\n",
        "sd_pipeline = StableDiffusionPipeline.from_pretrained(repo_ids[0], torch_dtype=torch.float16, use_safetensors=True).to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "configurations = [\"d-xl_images\", \"d-xl_color-prompt_images\", \"d-xl_color-direction-prompt_images\", \"d-xl_color-texture-prompt_images\", \"d-color-texture_images\", \"d_color-texture-feather_images\"]\n",
        "configuration = configurations[5]\n",
        "prompts = [\n",
        "    \"\"\"A detailed, high-resolution image of a blue bulbul.\"\"\",\n",
        "    \"\"\"A detailed, high-resolution image of a blue bulbul, perched elegantly on a sturdy branch of a lush, green tree.\"\"\",\n",
        "    \"\"\"A detailed, high-resolution image of a blue bulbul, perched elegantly on a sturdy branch of a lush, green tree.\n",
        "    The bulbul's feathers are covered in rain droplets, reflecting the surrounding environment.\"\"\",\n",
        "    \"\"\"A detailed, high-resolution image of a blue bulbul, perched elegantly on a sturdy branch of a lush, green tree.\n",
        "    The bulbul's feathers are covered in rain droplets, reflecting the surrounding environment, adding depth to the scene.\"\"\",\n",
        "]\n",
        "configs = [\n",
        "    \"d_res-color\",\n",
        "    \"d_res-color-environment\",\n",
        "    \"d_res-color-environment-texture\",\n",
        "    \"d_res-color-environment-texture-description\"\n",
        "]\n",
        "totals = [\n",
        "    50,\n",
        "    500\n",
        "]"
      ],
      "metadata": {
        "id": "dKDg8E9ZxgXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate images"
      ],
      "metadata": {
        "id": "QvyJ3a1uLKyF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vF8L3EmSNjTK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "for prompt, config in zip(prompts, configs):\n",
        "  if config != configs[-1]:\n",
        "    continue\n",
        "\n",
        "  total = totals[1]\n",
        "  # for total in totals:\n",
        "  for i in range(0, total, 5):\n",
        "    images = sd_pipeline(\n",
        "        prompt = prompt,\n",
        "        num_images_per_prompt = 5,\n",
        "    ).images\n",
        "\n",
        "    os.makedirs(f\"/content/drive/MyDrive/cv/{config}_{str(total)}\", exist_ok=True)\n",
        "    for j in range(0, 5, 1):\n",
        "      index = i + j\n",
        "      images[j].save(f\"/content/drive/MyDrive/cv/{config}_{str(total)}/image{index}.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Inception Embedding Model"
      ],
      "metadata": {
        "id": "7CdSRG-yjrBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sanity check"
      ],
      "metadata": {
        "id": "z5yRjJjFG7-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
      ],
      "metadata": {
        "id": "5tFoK5BdGxA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\"\n",
        "\n",
        "def load_inception_v3():\n",
        "  model = inception_v3(weights=Inception_V3_Weights.DEFAULT, transform_input=True).eval()\n",
        "  # model.fc = torch.nn.Identity()\n",
        "  return model\n",
        "\n",
        "\n",
        "def inception_transforms():\n",
        "  return transforms.Compose(\n",
        "    [\n",
        "      transforms.Resize(299),\n",
        "      transforms.CenterCrop(299),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Lambda(lambda x: x.expand(3, -1, -1)),\n",
        "    ]\n",
        "  )\n",
        "\n",
        "\n",
        "def get_images_embeddings(images, random_indices, no_repetitions, batch_size=64, device=torch.device(\"cpu\")):\n",
        "    if type(device) == str:\n",
        "        device = torch.device(device)\n",
        "\n",
        "    model = load_inception_v3().to(device)\n",
        "    transform = inception_transforms()\n",
        "\n",
        "    uids = []\n",
        "    embeddings = []\n",
        "    for index, batch in enumerate(data_utils.to_batches(images, batch_size)):\n",
        "        if index == 0:\n",
        "          x = torch.stack([transform(img) for img in batch for i in range(no_repetitions)], 0).to(device)\n",
        "        else:\n",
        "          x = torch.stack([transform(img) for img in batch], 0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(x).to(device)\n",
        "\n",
        "        if type(output) == list:\n",
        "            output = output[0]\n",
        "\n",
        "        embeddings.append(output.squeeze().cpu().numpy())\n",
        "    return np.concatenate(embeddings, 0)\n",
        "\n",
        "\n",
        "def get_pixel_images(images, random_indices, no_repetitions):\n",
        "  imgs = []\n",
        "  for k, image in enumerate(images):\n",
        "    if k == 0:\n",
        "      imgs.extend([image for _ in range(no_repetitions)])\n",
        "    else:\n",
        "      imgs.append(image)\n",
        "  return imgs\n",
        "\n",
        "\n",
        "vendi_scores = []\n",
        "total = totals[0]\n",
        "for l, configuration in enumerate(configs):\n",
        "  print(f\"Configuration: {configuration}\")\n",
        "  config_scores = []\n",
        "\n",
        "  image_names = os.listdir(f'/content/drive/MyDrive/cv/{configuration}_{total}/')\n",
        "  all_images = [Image.open(f\"/content/drive/MyDrive/cv/{configuration}_{total}/{img_name}\") for img_name in image_names]\n",
        "  for no_samples in [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]:\n",
        "    for no_reps in [1, 5, 10, 15, 50]:\n",
        "      random_indices = random.sample(sorted(np.arange(50)), no_samples)\n",
        "\n",
        "      images = random.sample(all_images, no_samples)\n",
        "\n",
        "      embeddings = get_images_embeddings(images, random_indices, no_reps, batch_size=5, device=torch.device(\"cuda\"))\n",
        "      inception_vs = vendi.score_X(embeddings)\n",
        "\n",
        "      pixel_images = get_pixel_images(images, random_indices, no_reps)\n",
        "      pixel_vs = image_utils.pixel_vendi_score(pixel_images)\n",
        "\n",
        "      print(f\"{no_samples} samples {no_reps} repetitions\")\n",
        "      print(f\"inception_vs: {inception_vs}, pixel_vs: {pixel_vs}\")\n",
        "      config_scores.append({\n",
        "          \"samples\": no_samples,\n",
        "          \"repetitions\": no_reps,\n",
        "          \"scores\": {\"inception_vs\": str(inception_vs), \"pixel_vs\": str(pixel_vs)}\n",
        "      })\n",
        "\n",
        "  vendi_scores.append({\n",
        "      \"configuration\": configuration,\n",
        "      \"config_scores\": config_scores\n",
        "  })\n",
        "\n",
        "  with open(f\"/content/drive/MyDrive/cv/vs_all-configs.jsonl\", \"w\") as jsonfile:\n",
        "    json.dump(vendi_scores, jsonfile)"
      ],
      "metadata": {
        "id": "OSG34sUwVhsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_inception(pretrained=True, pool=True):\n",
        "    if pretrained:\n",
        "        weights = Inception_V3_Weights.DEFAULT\n",
        "    else:\n",
        "        weights = None\n",
        "    model = inception_v3(\n",
        "        weights=weights, transform_input=True\n",
        "    ).eval()\n",
        "    if pool:\n",
        "        model.fc = nn.Identity()\n",
        "    return model\n",
        "\n",
        "\n",
        "def inception_transforms():\n",
        "    return transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(299),\n",
        "            transforms.CenterCrop(299),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Lambda(lambda x: x.expand(3, -1, -1)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "def get_embeddings(\n",
        "    images,\n",
        "    no_repetitions=None,\n",
        "    model=None,\n",
        "    transform=None,\n",
        "    batch_size=64,\n",
        "    device=torch.device(\"cpu\"),\n",
        "):\n",
        "    if type(device) == str:\n",
        "        device = torch.device(device)\n",
        "    if model is None:\n",
        "        model = get_inception(pretrained=True, pool=True).to(device)\n",
        "        transform = inception_transforms()\n",
        "    if transform is None:\n",
        "        transform = transforms.ToTensor()\n",
        "    uids = []\n",
        "    embeddings = []\n",
        "    for batch_id, batch in enumerate(data_utils.to_batches(images, batch_size)):\n",
        "        x = [torch.stack([transform(img) for img in batch], 0).to(device)]\n",
        "        if batch_id == 0 and no_repetitions > 1:\n",
        "          first_image_repeated = torch.stack([transform(batch[0]) for _ in range(no_repetitions-1)], 0).to(device)\n",
        "          x.extend([first_image_repeated])\n",
        "        x = torch.cat(x, 0)\n",
        "        with torch.no_grad():\n",
        "            output = model(x)\n",
        "        if type(output) == list:\n",
        "            output = output[0]\n",
        "        embeddings.append(output.squeeze().cpu().numpy())\n",
        "    return np.concatenate(embeddings, 0)\n",
        "\n",
        "def embedding_vendi_score(\n",
        "    images, no_repetitions, batch_size=64, device=\"cpu\", model=None, transform=None\n",
        "):\n",
        "    X = get_embeddings(\n",
        "        images,\n",
        "        no_repetitions,\n",
        "        batch_size=batch_size,\n",
        "        device=device,\n",
        "        model=model,\n",
        "        transform=transform,\n",
        "    )\n",
        "    n, d = X.shape\n",
        "    if n < d:\n",
        "      return vendi.score_X(X)\n",
        "    return vendi.score_dual(X)\n",
        "\n",
        "\n",
        "def pixel_vendi_score(images, random_indices, no_repetitions):\n",
        "  imgs = []\n",
        "  for k, image in enumerate(images):\n",
        "    if k == 0 and no_repetitions > 1:\n",
        "      imgs.extend([image for _ in range(no_repetitions)])\n",
        "    else:\n",
        "      imgs.append(image)\n",
        "  return image_utils.pixel_vendi_score(imgs)"
      ],
      "metadata": {
        "id": "rVXjiQywy6zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total = totals[0]\n",
        "vendi_scores = []\n",
        "for l, configuration in enumerate(configs):\n",
        "  print(f\"Configuration: {configuration}\")\n",
        "  config_scores = []\n",
        "  image_names = os.listdir(f'/content/drive/MyDrive/cv/{configuration}_{total}/')\n",
        "  all_images = [Image.open(f\"/content/drive/MyDrive/cv/{configuration}_{total}/{img_name}\") for img_name in image_names]\n",
        "  for no_samples in [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]:\n",
        "    for no_reps in [1, 5, 10, 15, 50]:\n",
        "      random_indices = random.sample(sorted(np.arange(50)), no_samples)\n",
        "      images = random.sample(all_images, no_samples)\n",
        "      inception_vs = embedding_vendi_score(images, no_reps, batch_size=64, device=\"cuda\")\n",
        "      pixel_vs = pixel_vendi_score(images, random_indices, no_reps)\n",
        "\n",
        "      print(f\"{no_samples} samples {no_reps} repetitions\")\n",
        "      print(f\"inception_vs: {inception_vs}, pixel_vs: {pixel_vs}\")\n",
        "      config_scores.append({\n",
        "          \"samples\": no_samples,\n",
        "          \"repetitions\": no_reps,\n",
        "          \"scores\": {\"inception_vs\": str(inception_vs), \"pixel_vs\": str(pixel_vs)}\n",
        "      })\n",
        "\n",
        "  vendi_scores.append({\n",
        "      \"configuration\": configuration,\n",
        "      \"config_scores\": config_scores\n",
        "  })\n",
        "\n",
        "  with open(f\"/content/drive/MyDrive/cv/i_vs-p_vs-all_configs-2.jsonl\", \"w\") as jsonfile:\n",
        "    json.dump(vendi_scores, jsonfile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TDo4edU1lRD",
        "outputId": "5934aff2-bbce-4290-c92f-b05713833109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration: d_res-color\n",
            "5 samples 1 repetitions\n",
            "inception_vs: 1.6030148267745972, pixel_vs: 1.8105870937200514\n",
            "5 samples 5 repetitions\n",
            "inception_vs: 1.541734218597412, pixel_vs: 1.5900579701736932\n",
            "5 samples 10 repetitions\n",
            "inception_vs: 1.304497241973877, pixel_vs: 1.3661673251219757\n",
            "5 samples 15 repetitions\n",
            "inception_vs: 1.243733286857605, pixel_vs: 1.2354108223531883\n",
            "5 samples 50 repetitions\n",
            "inception_vs: 1.0923999547958374, pixel_vs: 1.1264660755229317\n",
            "10 samples 1 repetitions\n",
            "inception_vs: 2.016962766647339, pixel_vs: 1.8368403827505926\n",
            "10 samples 5 repetitions\n",
            "inception_vs: 1.8646939992904663, pixel_vs: 1.7056558370560717\n",
            "10 samples 10 repetitions\n",
            "inception_vs: 1.7855262756347656, pixel_vs: 1.6155841028538716\n",
            "10 samples 15 repetitions\n",
            "inception_vs: 1.5389010906219482, pixel_vs: 1.5111085519213243\n",
            "10 samples 50 repetitions\n",
            "inception_vs: 1.257485270500183, pixel_vs: 1.2261691630976679\n",
            "15 samples 1 repetitions\n",
            "inception_vs: 2.090667963027954, pixel_vs: 2.022248048094092\n",
            "15 samples 5 repetitions\n",
            "inception_vs: 1.9003850221633911, pixel_vs: 1.755963102841419\n",
            "15 samples 10 repetitions\n",
            "inception_vs: 1.7602649927139282, pixel_vs: 2.0036412466069495\n",
            "15 samples 15 repetitions\n",
            "inception_vs: 1.6382660865783691, pixel_vs: 1.7690288583615514\n",
            "15 samples 50 repetitions\n",
            "inception_vs: 1.412302017211914, pixel_vs: 1.3219014163753213\n",
            "20 samples 1 repetitions\n",
            "inception_vs: 2.077336072921753, pixel_vs: 2.199595531864947\n",
            "20 samples 5 repetitions\n",
            "inception_vs: 1.9782319068908691, pixel_vs: 2.0472802119341638\n",
            "20 samples 10 repetitions\n",
            "inception_vs: 1.969437599182129, pixel_vs: 1.8741153742239405\n",
            "20 samples 15 repetitions\n",
            "inception_vs: 1.9542287588119507, pixel_vs: 1.8496524620349326\n",
            "20 samples 50 repetitions\n",
            "inception_vs: 1.4830000400543213, pixel_vs: 1.4793333453968325\n",
            "25 samples 1 repetitions\n",
            "inception_vs: 2.2828257083892822, pixel_vs: 2.080501325891052\n",
            "25 samples 5 repetitions\n",
            "inception_vs: 2.2479684352874756, pixel_vs: 2.1029707469791563\n",
            "25 samples 10 repetitions\n",
            "inception_vs: 2.076373338699341, pixel_vs: 1.9236361194473819\n",
            "25 samples 15 repetitions\n",
            "inception_vs: 2.0052690505981445, pixel_vs: 1.893918524667818\n",
            "25 samples 50 repetitions\n",
            "inception_vs: 1.5300430059432983, pixel_vs: 1.5639442125493688\n",
            "30 samples 1 repetitions\n",
            "inception_vs: 2.243124008178711, pixel_vs: 2.2162561662369984\n",
            "30 samples 5 repetitions\n",
            "inception_vs: 2.172684669494629, pixel_vs: 2.068772759585727\n",
            "30 samples 10 repetitions\n",
            "inception_vs: 2.0616512298583984, pixel_vs: 2.042511240628747\n",
            "30 samples 15 repetitions\n",
            "inception_vs: 2.063581705093384, pixel_vs: 1.967689057583704\n",
            "30 samples 50 repetitions\n",
            "inception_vs: 1.6847480535507202, pixel_vs: 1.670205972173283\n",
            "35 samples 1 repetitions\n",
            "inception_vs: 2.3145880699157715, pixel_vs: 2.175088374058286\n",
            "35 samples 5 repetitions\n",
            "inception_vs: 2.2314178943634033, pixel_vs: 2.196500843457273\n",
            "35 samples 10 repetitions\n",
            "inception_vs: 2.190582752227783, pixel_vs: 2.0944559685056854\n",
            "35 samples 15 repetitions\n",
            "inception_vs: 2.1002094745635986, pixel_vs: 2.028727611356751\n",
            "35 samples 50 repetitions\n",
            "inception_vs: 1.7042932510375977, pixel_vs: 1.624962108749049\n",
            "40 samples 1 repetitions\n",
            "inception_vs: 2.4133808612823486, pixel_vs: 2.1994909138712995\n",
            "40 samples 5 repetitions\n",
            "inception_vs: 2.3394246101379395, pixel_vs: 2.2333043073500676\n",
            "40 samples 10 repetitions\n",
            "inception_vs: 2.248774766921997, pixel_vs: 2.1416972869424598\n",
            "40 samples 15 repetitions\n",
            "inception_vs: 2.2652664184570312, pixel_vs: 2.015777447835792\n",
            "40 samples 50 repetitions\n",
            "inception_vs: 1.787825345993042, pixel_vs: 1.6446114023482887\n",
            "45 samples 1 repetitions\n",
            "inception_vs: 2.3923873901367188, pixel_vs: 2.2701810316528315\n",
            "45 samples 5 repetitions\n",
            "inception_vs: 2.353921413421631, pixel_vs: 2.257709280564956\n",
            "45 samples 10 repetitions\n",
            "inception_vs: 2.2829432487487793, pixel_vs: 2.2144000586570947\n",
            "45 samples 15 repetitions\n",
            "inception_vs: 2.1999757289886475, pixel_vs: 2.0374491945715913\n",
            "45 samples 50 repetitions\n",
            "inception_vs: 1.713645339012146, pixel_vs: 1.7030899739942098\n",
            "50 samples 1 repetitions\n",
            "inception_vs: 2.4047274589538574, pixel_vs: 2.314508143188249\n",
            "50 samples 5 repetitions\n",
            "inception_vs: 2.3789422512054443, pixel_vs: 2.3048225914395006\n",
            "50 samples 10 repetitions\n",
            "inception_vs: 2.34185528755188, pixel_vs: 2.2869957037134903\n",
            "50 samples 15 repetitions\n",
            "inception_vs: 2.323408365249634, pixel_vs: 2.0935507006279286\n",
            "50 samples 50 repetitions\n",
            "inception_vs: 1.9062561988830566, pixel_vs: 1.894212568278912\n",
            "Configuration: d_res-color-environment\n",
            "5 samples 1 repetitions\n",
            "inception_vs: 1.8137743473052979, pixel_vs: 1.7712856039133413\n",
            "5 samples 5 repetitions\n",
            "inception_vs: 1.5031538009643555, pixel_vs: 1.4894843357423955\n",
            "5 samples 10 repetitions\n",
            "inception_vs: 1.4383429288864136, pixel_vs: 1.4043369914813841\n",
            "5 samples 15 repetitions\n",
            "inception_vs: 1.2973181009292603, pixel_vs: 1.335436767593611\n",
            "5 samples 50 repetitions\n",
            "inception_vs: 1.1366745233535767, pixel_vs: 1.169723049177689\n",
            "10 samples 1 repetitions\n",
            "inception_vs: 2.141389846801758, pixel_vs: 2.1825921998127646\n",
            "10 samples 5 repetitions\n",
            "inception_vs: 1.904185175895691, pixel_vs: 1.9392258178866009\n",
            "10 samples 10 repetitions\n",
            "inception_vs: 1.6715947389602661, pixel_vs: 1.7667096464982412\n",
            "10 samples 15 repetitions\n",
            "inception_vs: 1.5588551759719849, pixel_vs: 1.6140576670496698\n",
            "10 samples 50 repetitions\n",
            "inception_vs: 1.2691909074783325, pixel_vs: 1.3029032299294314\n",
            "15 samples 1 repetitions\n",
            "inception_vs: 2.189260959625244, pixel_vs: 2.27081089795606\n",
            "15 samples 5 repetitions\n",
            "inception_vs: 1.9973605871200562, pixel_vs: 2.1776204227650666\n",
            "15 samples 10 repetitions\n",
            "inception_vs: 2.074648141860962, pixel_vs: 1.9764784141074339\n",
            "15 samples 15 repetitions\n",
            "inception_vs: 1.7941302061080933, pixel_vs: 1.7963393510854886\n",
            "15 samples 50 repetitions\n",
            "inception_vs: 1.4752023220062256, pixel_vs: 1.371476031115265\n",
            "20 samples 1 repetitions\n",
            "inception_vs: 2.4288575649261475, pixel_vs: 2.5597264831235416\n",
            "20 samples 5 repetitions\n",
            "inception_vs: 2.1395046710968018, pixel_vs: 2.243823993297273\n",
            "20 samples 10 repetitions\n",
            "inception_vs: 1.9773883819580078, pixel_vs: 1.9226709205093877\n",
            "20 samples 15 repetitions\n",
            "inception_vs: 1.8504217863082886, pixel_vs: 2.0013283027543527\n",
            "20 samples 50 repetitions\n",
            "inception_vs: 1.535814642906189, pixel_vs: 1.5096264668720625\n",
            "25 samples 1 repetitions\n",
            "inception_vs: 2.4346442222595215, pixel_vs: 2.415721056352669\n",
            "25 samples 5 repetitions\n",
            "inception_vs: 2.3696272373199463, pixel_vs: 2.36638937510451\n",
            "25 samples 10 repetitions\n",
            "inception_vs: 2.1848487854003906, pixel_vs: 2.2777248536546497\n",
            "25 samples 15 repetitions\n",
            "inception_vs: 2.0590877532958984, pixel_vs: 2.2014623845805645\n",
            "25 samples 50 repetitions\n",
            "inception_vs: 1.5600579977035522, pixel_vs: 1.6138824659131166\n",
            "30 samples 1 repetitions\n",
            "inception_vs: 2.5040977001190186, pixel_vs: 2.5005815959033315\n",
            "30 samples 5 repetitions\n",
            "inception_vs: 2.474608898162842, pixel_vs: 2.4232284433269515\n",
            "30 samples 10 repetitions\n",
            "inception_vs: 2.352738380432129, pixel_vs: 2.4126419903628737\n",
            "30 samples 15 repetitions\n",
            "inception_vs: 2.2618954181671143, pixel_vs: 2.2382931353933815\n",
            "30 samples 50 repetitions\n",
            "inception_vs: 1.650191307067871, pixel_vs: 1.7456561475150882\n",
            "35 samples 1 repetitions\n",
            "inception_vs: 2.5426387786865234, pixel_vs: 2.556847627673441\n",
            "35 samples 5 repetitions\n",
            "inception_vs: 2.567246675491333, pixel_vs: 2.6001461248263915\n",
            "35 samples 10 repetitions\n",
            "inception_vs: 2.4104630947113037, pixel_vs: 2.4211523100306245\n",
            "35 samples 15 repetitions\n",
            "inception_vs: 2.290083408355713, pixel_vs: 2.431767556069925\n",
            "35 samples 50 repetitions\n",
            "inception_vs: 1.7368451356887817, pixel_vs: 1.7954833248054014\n",
            "40 samples 1 repetitions\n",
            "inception_vs: 2.5743067264556885, pixel_vs: 2.625684630424343\n",
            "40 samples 5 repetitions\n",
            "inception_vs: 2.426539182662964, pixel_vs: 2.627569765852544\n",
            "40 samples 10 repetitions\n",
            "inception_vs: 2.397634744644165, pixel_vs: 2.4725816094841724\n",
            "40 samples 15 repetitions\n",
            "inception_vs: 2.4100794792175293, pixel_vs: 2.482403714731665\n",
            "40 samples 50 repetitions\n",
            "inception_vs: 1.7898658514022827, pixel_vs: 1.8762993792034686\n",
            "45 samples 1 repetitions\n",
            "inception_vs: 2.6688594818115234, pixel_vs: 2.69862864440877\n",
            "45 samples 5 repetitions\n",
            "inception_vs: 2.5018668174743652, pixel_vs: 2.6097539083624413\n",
            "45 samples 10 repetitions\n",
            "inception_vs: 2.437345504760742, pixel_vs: 2.5356791993224355\n",
            "45 samples 15 repetitions\n",
            "inception_vs: 2.4235892295837402, pixel_vs: 2.5890820938622863\n",
            "45 samples 50 repetitions\n",
            "inception_vs: 1.9152488708496094, pixel_vs: 1.9557144868125225\n",
            "50 samples 1 repetitions\n",
            "inception_vs: 2.6388251781463623, pixel_vs: 2.7574149248504525\n",
            "50 samples 5 repetitions\n",
            "inception_vs: 2.6483006477355957, pixel_vs: 2.750037323706162\n",
            "50 samples 10 repetitions\n",
            "inception_vs: 2.603691339492798, pixel_vs: 2.6858200719669174\n",
            "50 samples 15 repetitions\n",
            "inception_vs: 2.455406665802002, pixel_vs: 2.5090625923561416\n",
            "50 samples 50 repetitions\n",
            "inception_vs: 1.9293830394744873, pixel_vs: 2.017362095682117\n",
            "Configuration: d_res-color-environment-texture\n",
            "5 samples 1 repetitions\n",
            "inception_vs: 1.894364356994629, pixel_vs: 1.7915146945931697\n",
            "5 samples 5 repetitions\n",
            "inception_vs: 1.4944146871566772, pixel_vs: 1.667150776356372\n",
            "5 samples 10 repetitions\n",
            "inception_vs: 1.2953943014144897, pixel_vs: 1.4286467592073302\n",
            "5 samples 15 repetitions\n",
            "inception_vs: 1.3382984399795532, pixel_vs: 1.3491731863082534\n",
            "5 samples 50 repetitions\n",
            "inception_vs: 1.1599687337875366, pixel_vs: 1.1071447794640876\n",
            "10 samples 1 repetitions\n",
            "inception_vs: 2.0074830055236816, pixel_vs: 2.115972570766739\n",
            "10 samples 5 repetitions\n",
            "inception_vs: 1.919385313987732, pixel_vs: 1.8970382864521922\n",
            "10 samples 10 repetitions\n",
            "inception_vs: 1.7190321683883667, pixel_vs: 1.6746622927207042\n",
            "10 samples 15 repetitions\n",
            "inception_vs: 1.5615378618240356, pixel_vs: 1.5889438177993274\n",
            "10 samples 50 repetitions\n",
            "inception_vs: 1.2325959205627441, pixel_vs: 1.2730033499942996\n",
            "15 samples 1 repetitions\n",
            "inception_vs: 2.220741033554077, pixel_vs: 2.2801752785124556\n",
            "15 samples 5 repetitions\n",
            "inception_vs: 2.0831074714660645, pixel_vs: 2.1375070946115082\n",
            "15 samples 10 repetitions\n",
            "inception_vs: 1.9396955966949463, pixel_vs: 2.0391267368046533\n",
            "15 samples 15 repetitions\n",
            "inception_vs: 1.9734618663787842, pixel_vs: 1.9865062116381875\n",
            "15 samples 50 repetitions\n",
            "inception_vs: 1.3466955423355103, pixel_vs: 1.4507071616198774\n",
            "20 samples 1 repetitions\n",
            "inception_vs: 2.0467326641082764, pixel_vs: 2.450013148228476\n",
            "20 samples 5 repetitions\n",
            "inception_vs: 2.2200539112091064, pixel_vs: 2.2440298227820445\n",
            "20 samples 10 repetitions\n",
            "inception_vs: 2.0215861797332764, pixel_vs: 2.0632293746868715\n",
            "20 samples 15 repetitions\n",
            "inception_vs: 1.8817845582962036, pixel_vs: 1.916481400322967\n",
            "20 samples 50 repetitions\n",
            "inception_vs: 1.73827064037323, pixel_vs: 1.5422740963495696\n",
            "25 samples 1 repetitions\n",
            "inception_vs: 2.254298686981201, pixel_vs: 2.392169436872069\n",
            "25 samples 5 repetitions\n",
            "inception_vs: 2.1923699378967285, pixel_vs: 2.3663635172901856\n",
            "25 samples 10 repetitions\n",
            "inception_vs: 2.2050368785858154, pixel_vs: 2.2965574654380454\n",
            "25 samples 15 repetitions\n",
            "inception_vs: 2.1097116470336914, pixel_vs: 2.1536700416808263\n",
            "25 samples 50 repetitions\n",
            "inception_vs: 1.7336877584457397, pixel_vs: 1.5570696364301093\n",
            "30 samples 1 repetitions\n",
            "inception_vs: 2.353623867034912, pixel_vs: 2.483757473881331\n",
            "30 samples 5 repetitions\n",
            "inception_vs: 2.2253613471984863, pixel_vs: 2.498297408828282\n",
            "30 samples 10 repetitions\n",
            "inception_vs: 2.227480173110962, pixel_vs: 2.358234064222775\n",
            "30 samples 15 repetitions\n",
            "inception_vs: 2.135650157928467, pixel_vs: 2.1795641270600314\n",
            "30 samples 50 repetitions\n",
            "inception_vs: 1.7591438293457031, pixel_vs: 1.808271606907685\n",
            "35 samples 1 repetitions\n",
            "inception_vs: 2.42848539352417, pixel_vs: 2.6580675988209066\n",
            "35 samples 5 repetitions\n",
            "inception_vs: 2.5097806453704834, pixel_vs: 2.5053427177409917\n",
            "35 samples 10 repetitions\n",
            "inception_vs: 2.328481435775757, pixel_vs: 2.399640930834295\n",
            "35 samples 15 repetitions\n",
            "inception_vs: 2.15494704246521, pixel_vs: 2.357913166848962\n",
            "35 samples 50 repetitions\n",
            "inception_vs: 1.6945480108261108, pixel_vs: 1.8317100500635917\n",
            "40 samples 1 repetitions\n",
            "inception_vs: 2.450774908065796, pixel_vs: 2.720088321201311\n",
            "40 samples 5 repetitions\n",
            "inception_vs: 2.5526394844055176, pixel_vs: 2.6403423186770842\n",
            "40 samples 10 repetitions\n",
            "inception_vs: 2.270479679107666, pixel_vs: 2.4486270226218507\n",
            "40 samples 15 repetitions\n",
            "inception_vs: 2.329413890838623, pixel_vs: 2.4545804802268987\n",
            "40 samples 50 repetitions\n",
            "inception_vs: 1.8331791162490845, pixel_vs: 1.9476616766590507\n",
            "45 samples 1 repetitions\n",
            "inception_vs: 2.57088041305542, pixel_vs: 2.7091079335259827\n",
            "45 samples 5 repetitions\n",
            "inception_vs: 2.4426357746124268, pixel_vs: 2.6050098111827076\n",
            "45 samples 10 repetitions\n",
            "inception_vs: 2.3374135494232178, pixel_vs: 2.539861039314\n",
            "45 samples 15 repetitions\n",
            "inception_vs: 2.4008185863494873, pixel_vs: 2.46726881686878\n",
            "45 samples 50 repetitions\n",
            "inception_vs: 1.915298342704773, pixel_vs: 1.984477607146871\n",
            "50 samples 1 repetitions\n",
            "inception_vs: 2.593738555908203, pixel_vs: 2.7392325977505587\n",
            "50 samples 5 repetitions\n",
            "inception_vs: 2.5370757579803467, pixel_vs: 2.7011926429381043\n",
            "50 samples 10 repetitions\n",
            "inception_vs: 2.48549222946167, pixel_vs: 2.581774889950927\n",
            "50 samples 15 repetitions\n",
            "inception_vs: 2.393558979034424, pixel_vs: 2.5085839883558614\n",
            "50 samples 50 repetitions\n",
            "inception_vs: 1.9347907304763794, pixel_vs: 2.064870648069896\n",
            "Configuration: d_res-color-environment-texture-description\n",
            "5 samples 1 repetitions\n",
            "inception_vs: 1.7299697399139404, pixel_vs: 1.6973233229273754\n",
            "5 samples 5 repetitions\n",
            "inception_vs: 1.6262118816375732, pixel_vs: 1.4845518341025734\n",
            "5 samples 10 repetitions\n",
            "inception_vs: 1.4814642667770386, pixel_vs: 1.4353473133069752\n",
            "5 samples 15 repetitions\n",
            "inception_vs: 1.3580957651138306, pixel_vs: 1.2984679442403575\n",
            "5 samples 50 repetitions\n",
            "inception_vs: 1.1628990173339844, pixel_vs: 1.1255643925153442\n",
            "10 samples 1 repetitions\n",
            "inception_vs: 1.9240351915359497, pixel_vs: 2.1201702327139347\n",
            "10 samples 5 repetitions\n",
            "inception_vs: 1.938301920890808, pixel_vs: 2.1889161811964373\n",
            "10 samples 10 repetitions\n",
            "inception_vs: 1.620400309562683, pixel_vs: 1.7953912717049048\n",
            "10 samples 15 repetitions\n",
            "inception_vs: 1.6708624362945557, pixel_vs: 1.6024096993359545\n",
            "10 samples 50 repetitions\n",
            "inception_vs: 1.2649458646774292, pixel_vs: 1.2888332125939894\n",
            "15 samples 1 repetitions\n",
            "inception_vs: 2.0995442867279053, pixel_vs: 2.0841149775861822\n",
            "15 samples 5 repetitions\n",
            "inception_vs: 1.9917871952056885, pixel_vs: 2.0813451065014212\n",
            "15 samples 10 repetitions\n",
            "inception_vs: 1.7976142168045044, pixel_vs: 1.7365932354701286\n",
            "15 samples 15 repetitions\n",
            "inception_vs: 1.8975353240966797, pixel_vs: 1.8300163720014853\n",
            "15 samples 50 repetitions\n",
            "inception_vs: 1.366690993309021, pixel_vs: 1.3829226656138671\n",
            "20 samples 1 repetitions\n",
            "inception_vs: 2.2616047859191895, pixel_vs: 2.1738369598437663\n",
            "20 samples 5 repetitions\n",
            "inception_vs: 2.289965867996216, pixel_vs: 2.150943655360524\n",
            "20 samples 10 repetitions\n",
            "inception_vs: 2.082183361053467, pixel_vs: 1.9717360385191203\n",
            "20 samples 15 repetitions\n",
            "inception_vs: 2.074676752090454, pixel_vs: 1.9130205314450242\n",
            "20 samples 50 repetitions\n",
            "inception_vs: 1.4229575395584106, pixel_vs: 1.3895324823659922\n",
            "25 samples 1 repetitions\n",
            "inception_vs: 2.4114580154418945, pixel_vs: 2.574455537137832\n",
            "25 samples 5 repetitions\n",
            "inception_vs: 2.217510223388672, pixel_vs: 2.2137260169121133\n",
            "25 samples 10 repetitions\n",
            "inception_vs: 2.132981300354004, pixel_vs: 2.1933990982820752\n",
            "25 samples 15 repetitions\n",
            "inception_vs: 1.9414818286895752, pixel_vs: 2.047928707639459\n",
            "25 samples 50 repetitions\n",
            "inception_vs: 1.6119736433029175, pixel_vs: 1.5636760056969505\n",
            "30 samples 1 repetitions\n",
            "inception_vs: 2.5106444358825684, pixel_vs: 2.3755843548175464\n",
            "30 samples 5 repetitions\n",
            "inception_vs: 2.363743305206299, pixel_vs: 2.405689854332796\n",
            "30 samples 10 repetitions\n",
            "inception_vs: 2.159876823425293, pixel_vs: 2.129258362005228\n",
            "30 samples 15 repetitions\n",
            "inception_vs: 2.1837780475616455, pixel_vs: 2.182486950279976\n",
            "30 samples 50 repetitions\n",
            "inception_vs: 1.728715419769287, pixel_vs: 1.737624787516911\n",
            "35 samples 1 repetitions\n",
            "inception_vs: 2.365185260772705, pixel_vs: 2.468574725727695\n",
            "35 samples 5 repetitions\n",
            "inception_vs: 2.389556646347046, pixel_vs: 2.3494667524690467\n",
            "35 samples 10 repetitions\n",
            "inception_vs: 2.342386484146118, pixel_vs: 2.207605563567521\n",
            "35 samples 15 repetitions\n",
            "inception_vs: 2.1681220531463623, pixel_vs: 2.2165242806479464\n",
            "35 samples 50 repetitions\n",
            "inception_vs: 1.8759217262268066, pixel_vs: 1.811769577464895\n",
            "40 samples 1 repetitions\n",
            "inception_vs: 2.5067830085754395, pixel_vs: 2.4889604001000847\n",
            "40 samples 5 repetitions\n",
            "inception_vs: 2.4612345695495605, pixel_vs: 2.4714286017298113\n",
            "40 samples 10 repetitions\n",
            "inception_vs: 2.3614182472229004, pixel_vs: 2.4002430083795816\n",
            "40 samples 15 repetitions\n",
            "inception_vs: 2.334397554397583, pixel_vs: 2.354047460788393\n",
            "40 samples 50 repetitions\n",
            "inception_vs: 1.7800372838974, pixel_vs: 1.8676825405972093\n",
            "45 samples 1 repetitions\n",
            "inception_vs: 2.5680036544799805, pixel_vs: 2.621427649803169\n",
            "45 samples 5 repetitions\n",
            "inception_vs: 2.4470415115356445, pixel_vs: 2.4993357476705245\n",
            "45 samples 10 repetitions\n",
            "inception_vs: 2.413071393966675, pixel_vs: 2.4027766292780557\n",
            "45 samples 15 repetitions\n",
            "inception_vs: 2.292203426361084, pixel_vs: 2.3782064501494373\n",
            "45 samples 50 repetitions\n",
            "inception_vs: 1.8291146755218506, pixel_vs: 1.818608031416215\n",
            "50 samples 1 repetitions\n",
            "inception_vs: 2.5546834468841553, pixel_vs: 2.602185636560389\n",
            "50 samples 5 repetitions\n",
            "inception_vs: 2.5081543922424316, pixel_vs: 2.5902106181890887\n",
            "50 samples 10 repetitions\n",
            "inception_vs: 2.491879463195801, pixel_vs: 2.4428315698123044\n",
            "50 samples 15 repetitions\n",
            "inception_vs: 2.3143062591552734, pixel_vs: 2.4400813261144694\n",
            "50 samples 50 repetitions\n",
            "inception_vs: 2.011685609817505, pixel_vs: 1.9607989562539476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total = totals[0]\n",
        "vendi_scores = []\n",
        "for l, configuration in enumerate(configs):\n",
        "  print(f\"Configuration: {configuration}\")\n",
        "  config_scores = []\n",
        "  image_names = os.listdir(f'/content/drive/MyDrive/cv/{configuration}_{total}/')\n",
        "  all_images = [Image.open(f\"/content/drive/MyDrive/cv/{configuration}_{total}/{img_name}\") for img_name in image_names]\n",
        "  for no_samples in [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]:\n",
        "    for no_reps in [1]:\n",
        "      random_indices = random.sample(sorted(np.arange(50)), no_samples)\n",
        "      images = random.sample(all_images, no_samples)\n",
        "      inception_vs = embedding_vendi_score(images, no_reps, batch_size=64, device=\"cuda\")\n",
        "      pixel_vs = pixel_vendi_score(images, random_indices, no_reps)\n",
        "\n",
        "      print(f\"{no_samples} samples {no_reps} repetitions\")\n",
        "      print(f\"inception_vs: {inception_vs}, pixel_vs: {pixel_vs}\")\n",
        "      config_scores.append({\n",
        "          \"samples\": no_samples,\n",
        "          \"repetitions\": no_reps,\n",
        "          \"scores\": {\"inception_vs\": str(inception_vs), \"pixel_vs\": str(pixel_vs)}\n",
        "      })\n",
        "\n",
        "  vendi_scores.append({\n",
        "      \"configuration\": configuration,\n",
        "      \"config_scores\": config_scores\n",
        "  })\n",
        "\n",
        "  with open(f\"/content/drive/MyDrive/cv/i_vs-p_vs-all_configs-3.jsonl\", \"w\") as jsonfile:\n",
        "    json.dump(vendi_scores, jsonfile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDqWvOf6uj8E",
        "outputId": "a9f132e5-0152-4298-e371-b455ab054b6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration: d_res-color\n",
            "5 samples 1 repetitions\n",
            "inception_vs: 1.6457939147949219, pixel_vs: 1.62077871699863\n",
            "10 samples 1 repetitions\n",
            "inception_vs: 1.9574440717697144, pixel_vs: 2.0534624725828885\n",
            "15 samples 1 repetitions\n",
            "inception_vs: 1.904537558555603, pixel_vs: 1.9494735269210823\n",
            "20 samples 1 repetitions\n",
            "inception_vs: 2.1980621814727783, pixel_vs: 1.9734183869516897\n",
            "25 samples 1 repetitions\n",
            "inception_vs: 2.259702205657959, pixel_vs: 2.1665055234257133\n",
            "30 samples 1 repetitions\n",
            "inception_vs: 2.234273672103882, pixel_vs: 2.116802627712444\n",
            "35 samples 1 repetitions\n",
            "inception_vs: 2.3073694705963135, pixel_vs: 2.2134627124512063\n",
            "40 samples 1 repetitions\n",
            "inception_vs: 2.3404839038848877, pixel_vs: 2.2386366991385556\n",
            "45 samples 1 repetitions\n",
            "inception_vs: 2.3809893131256104, pixel_vs: 2.335574460945557\n",
            "50 samples 1 repetitions\n",
            "inception_vs: 2.4047281742095947, pixel_vs: 2.314508143188248\n",
            "Configuration: d_res-color-environment\n",
            "5 samples 1 repetitions\n",
            "inception_vs: 1.7544032335281372, pixel_vs: 1.776391800354661\n",
            "10 samples 1 repetitions\n",
            "inception_vs: 2.1817691326141357, pixel_vs: 2.0848204825765495\n",
            "15 samples 1 repetitions\n",
            "inception_vs: 2.1910831928253174, pixel_vs: 2.2671051786450778\n",
            "20 samples 1 repetitions\n",
            "inception_vs: 2.4119045734405518, pixel_vs: 2.3253109871145017\n",
            "25 samples 1 repetitions\n",
            "inception_vs: 2.41801118850708, pixel_vs: 2.5635547046087357\n",
            "30 samples 1 repetitions\n",
            "inception_vs: 2.5083210468292236, pixel_vs: 2.7184943182819694\n",
            "35 samples 1 repetitions\n",
            "inception_vs: 2.5783653259277344, pixel_vs: 2.5931072906866937\n",
            "40 samples 1 repetitions\n",
            "inception_vs: 2.6893768310546875, pixel_vs: 2.670972276333329\n",
            "45 samples 1 repetitions\n",
            "inception_vs: 2.5948331356048584, pixel_vs: 2.6906060361335813\n",
            "50 samples 1 repetitions\n",
            "inception_vs: 2.638824224472046, pixel_vs: 2.757414924850454\n",
            "Configuration: d_res-color-environment-texture\n",
            "5 samples 1 repetitions\n",
            "inception_vs: 1.8037623167037964, pixel_vs: 1.5861526120427794\n",
            "10 samples 1 repetitions\n",
            "inception_vs: 2.116511344909668, pixel_vs: 2.1703936259827623\n",
            "15 samples 1 repetitions\n",
            "inception_vs: 2.2997775077819824, pixel_vs: 2.151053538028452\n",
            "20 samples 1 repetitions\n",
            "inception_vs: 2.2855217456817627, pixel_vs: 2.26074545563268\n",
            "25 samples 1 repetitions\n",
            "inception_vs: 2.2623040676116943, pixel_vs: 2.3984718917788013\n",
            "30 samples 1 repetitions\n",
            "inception_vs: 2.4696638584136963, pixel_vs: 2.55646723604944\n",
            "35 samples 1 repetitions\n",
            "inception_vs: 2.5339162349700928, pixel_vs: 2.6508488764249027\n",
            "40 samples 1 repetitions\n",
            "inception_vs: 2.523777961730957, pixel_vs: 2.595125894509541\n",
            "45 samples 1 repetitions\n",
            "inception_vs: 2.553600549697876, pixel_vs: 2.677355679765731\n",
            "50 samples 1 repetitions\n",
            "inception_vs: 2.5937397480010986, pixel_vs: 2.739232597750557\n",
            "Configuration: d_res-color-environment-texture-description\n",
            "5 samples 1 repetitions\n",
            "inception_vs: 1.7848482131958008, pixel_vs: 1.890619884040198\n",
            "10 samples 1 repetitions\n",
            "inception_vs: 2.0785880088806152, pixel_vs: 1.9797417428789106\n",
            "15 samples 1 repetitions\n",
            "inception_vs: 2.288654088973999, pixel_vs: 2.216375931151585\n",
            "20 samples 1 repetitions\n",
            "inception_vs: 2.282274007797241, pixel_vs: 2.293677003890981\n",
            "25 samples 1 repetitions\n",
            "inception_vs: 2.3487746715545654, pixel_vs: 2.310358826270659\n",
            "30 samples 1 repetitions\n",
            "inception_vs: 2.332808494567871, pixel_vs: 2.40184249446058\n",
            "35 samples 1 repetitions\n",
            "inception_vs: 2.457345485687256, pixel_vs: 2.502137223694521\n",
            "40 samples 1 repetitions\n",
            "inception_vs: 2.446861743927002, pixel_vs: 2.5218566679205736\n",
            "45 samples 1 repetitions\n",
            "inception_vs: 2.5196220874786377, pixel_vs: 2.506491172622096\n",
            "50 samples 1 repetitions\n",
            "inception_vs: 2.554682970046997, pixel_vs: 2.6021856365603906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total = totals[1]\n",
        "vendi_scores = []\n",
        "for l, configuration in enumerate(configs):\n",
        "  if configuration == configs[-1]:\n",
        "    print(f\"Configuration: {configuration}\")\n",
        "    config_scores = []\n",
        "    image_names = os.listdir(f'/content/drive/MyDrive/cv/{configuration}_{total}/')\n",
        "    all_images = [Image.open(f\"/content/drive/MyDrive/cv/{configuration}_{total}/{img_name}\") for img_name in image_names]\n",
        "    for no_samples in [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 500]:\n",
        "      for no_reps in [1]:\n",
        "        images = random.sample(all_images, no_samples)\n",
        "        inception_vs = embedding_vendi_score(images, no_reps, batch_size=64, device=\"cuda\")\n",
        "        pixel_vs = pixel_vendi_score(images, random_indices, no_reps)\n",
        "\n",
        "        print(f\"{no_samples} samples {no_reps} repetitions\")\n",
        "        print(f\"inception_vs: {inception_vs}, pixel_vs: {pixel_vs}\")\n",
        "        config_scores.append({\n",
        "            \"samples\": no_samples,\n",
        "            \"repetitions\": no_reps,\n",
        "            \"scores\": {\"inception_vs\": str(inception_vs), \"pixel_vs\": str(pixel_vs)}\n",
        "        })\n",
        "\n",
        "    vendi_scores.append({\n",
        "        \"configuration\": configuration,\n",
        "        \"config_scores\": config_scores\n",
        "    })\n",
        "\n",
        "    with open(f\"/content/drive/MyDrive/cv/i_vs-p_vs-all_configs-4.jsonl\", \"w\") as jsonfile:\n",
        "      json.dump(vendi_scores, jsonfile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKD0zTNDyDqX",
        "outputId": "9ac6864c-6663-41ab-abd3-21e6d132a9db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration: d_res-color-environment-texture-description\n",
            "5 samples 1 repetitions\n",
            "inception_vs: 1.7365570068359375, pixel_vs: 1.7863884245786255\n",
            "10 samples 1 repetitions\n",
            "inception_vs: 1.9061369895935059, pixel_vs: 1.9660638416973386\n",
            "15 samples 1 repetitions\n",
            "inception_vs: 2.3202710151672363, pixel_vs: 2.1729437518305232\n",
            "20 samples 1 repetitions\n",
            "inception_vs: 2.4356980323791504, pixel_vs: 2.3547579552014253\n",
            "25 samples 1 repetitions\n",
            "inception_vs: 2.1505815982818604, pixel_vs: 2.3074337637473423\n",
            "30 samples 1 repetitions\n",
            "inception_vs: 2.457899808883667, pixel_vs: 2.4936577610164425\n",
            "35 samples 1 repetitions\n",
            "inception_vs: 2.4613442420959473, pixel_vs: 2.4852009734468146\n",
            "40 samples 1 repetitions\n",
            "inception_vs: 2.4764363765716553, pixel_vs: 2.5305571252917876\n",
            "45 samples 1 repetitions\n",
            "inception_vs: 2.496657371520996, pixel_vs: 2.5052282176822316\n",
            "50 samples 1 repetitions\n",
            "inception_vs: 2.353614091873169, pixel_vs: 2.5277263684897893\n",
            "500 samples 1 repetitions\n",
            "inception_vs: 2.9232311248779297, pixel_vs: 3.2966539228030927\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6c36a62f53ac40d58f7854a865912bc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78f00809c91e4940a967e337c3767a04",
              "IPY_MODEL_422c5922e5c345cf885de5f40be5af26",
              "IPY_MODEL_9ec0ab7f66344bd585e39b89320b078b"
            ],
            "layout": "IPY_MODEL_14c46ea1a6e6435eac3cc291b1694b23"
          }
        },
        "78f00809c91e4940a967e337c3767a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29dedc07eed04018847e13aa81996866",
            "placeholder": "​",
            "style": "IPY_MODEL_5a2caf2f17a64d1b9747915f4b2476c3",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "422c5922e5c345cf885de5f40be5af26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_087e09c98ca14c2b87125740a8761694",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39d0ff31f4da4077ad441676b251fd4a",
            "value": 7
          }
        },
        "9ec0ab7f66344bd585e39b89320b078b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_670006362981456a95057877f9adff64",
            "placeholder": "​",
            "style": "IPY_MODEL_c2d965d79f444f50befefedad5707777",
            "value": " 7/7 [00:24&lt;00:00,  2.68s/it]"
          }
        },
        "14c46ea1a6e6435eac3cc291b1694b23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29dedc07eed04018847e13aa81996866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a2caf2f17a64d1b9747915f4b2476c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "087e09c98ca14c2b87125740a8761694": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39d0ff31f4da4077ad441676b251fd4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "670006362981456a95057877f9adff64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2d965d79f444f50befefedad5707777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}